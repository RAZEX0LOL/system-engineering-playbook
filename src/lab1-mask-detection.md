# Лабораторная работа №1: Система контроля средств индивидуальной защиты

## Оглавление

- [Введение](#введение)
- [Задачи системы](#задачи-системы)
- [Целевая аудитория и области применения](#целевая-аудитория-и-области-применения)
- [Технологический стэк](#технологический-стэк)
- [Требования системы контроля СИЗ и их влияние на архитектуру](#требования-системы-контроля-сиз-и-их-влияние-на-архитектуру)
- [Архитектура нейронной сети](#архитектура-нейронной-сети)
- [Сравнение с альтернативными архитектурами](#сравнение-с-альтернативными-архитектурами)
- [Заключение](#заключение)
- [Источники](#источники)

---

## Введение

Данная документация описывает систему для автоматического мониторинга использования средств индивидуальной защиты органов дыхания в реальном времени с помощью алгоритмов компьютерного зрения.

## Задачи системы

- Захват видеопотока в реальном времени с веб-камеры, установленной в контролируемой зоне
- Детекция антропометрических объектов (лиц) в каждом кадре видео
- Классификация каждого обнаруженного лица по признаку наличия или отсутствия маски
- Визуализация результатов:
  - Обрамление лица зеленым прямоугольником при наличии маски.
  - Обрамление лица красным прямоугольником при отсутствии маски.

## Целевая аудитория и области применения

### Производственные предприятия (химические, металлургические, деревообрабатывающие):
- **Проблема:** Работники пренебрегают масками в цехах с запыленностью или испарениями.
- **Решение:** Установка камеры на входе в опасную зону. Система в реальном времени предупреждает мастеров о нарушителях.

### Строительные компании:
- **Проблема:** Рабочие не используют респираторы при работе с пылью, краской.
- **Решение:** Мониторинг на ключевых объектах стройплощадки для превентивного выявления нарушений.

### Медицинские учреждения (особенно стационары и лаборатории):
- **Проблема:** Соблюдение масочного режима для профилактики внутрибольничных инфекций.
- **Решение:** Контроль в холлах, коридорах и общих зонах для снижения рисков.

## Технологический стэк

### Язык программирования: Python

### Библиотеки и фреймворки:

- **TensorFlow/Keras** (≥2.0.0) — фреймворк машинного обучения
- **OpenCV** (≥4.2.0) — библиотека компьютерного зрения
- **NumPy** (≥1.18.0) — работа с массивами
- **imutils** (≥0.5.3) — утилиты обработки видео
- **scikit-learn** — инструменты машинного обучения
- **Tkinter** — графический интерфейс
- **PIL/Pillow** — обработка изображений
- **Matplotlib** — визуализация графиков обучения

### Отличительные особенности и преимущества

- **Работа в реальном времени:** Низкая задержка обработки.
- **Автоматизация:** Исключение человеческого фактора из процесса контроля.
- **Наглядность:** Цветовая индикация позволяет мгновенно оценить обстановку.
- **Простота внедрения:** Для работы требуется стандартная веб-камера и ПК.
- **Масштабируемость:** Архитектура позволяет в будущем дообучить модель на другие виды СИЗ (каски, защитные очки).

## Требования системы контроля СИЗ и их влияние на архитектуру

| Требование системы | Влияние на архитектуру | Реализация в выбранной модели |
|-------------------|------------------------|-------------------------------|
| Работа в реальном времени | Низкая задержка, высокая скорость инференса | MobileNetV2 оптимизирована для быстрого выполнения |
| Работа на доступном оборудовании | Низкие вычислительные требования, малый объем памяти | Облегченная архитектура Depthwise Separable Convolutions |
| Высокая точность распознавания | Способность извлекать сложные признаки | Transfer Learning с моделью, обученной на ImageNet |
| Устойчивость к изменениям условий | Робастность к освещению, ракурсам, частичным перекрытиям | Аугментация данных и мощный feature extractor |
| Ограниченный датасет для обучения | Эффективное обучение на небольшом количестве данных | Техника Transfer Learning |

## Архитектура нейронной сети

### Общая концепция: Transfer Learning (Трансферное обучение)

Система использует технику трансферного обучения - подход, при котором предварительно обученная на большом датасете (ImageNet) модель адаптируется для решения конкретной задачи. Это позволяет достичь высокой точности даже при ограниченном количестве обучающих данных.

### Описание архитектуры

**Параметры модели:**
- **Базовая модель:** MobileNetV2 с предобученными весами ImageNet
- **Входные данные:** Изображения 224×224×3 RGB
- **Аугментация данных:** ImageDataGenerator с трансформациями
- **Оптимизатор:** Adam с learning rate = 0.0001
- **Функция потерь:** Binary Crossentropy

**Конфигурация обучения:**
```python
INIT_LR = 0.0001           # Начальная скорость обучения
EPOCHS = 20                # Количество эпох
BS = 32                    # Размер батча
```

**Параметры аугментации:**
```python
aug = ImageDataGenerator(
    rotation_range=20,          # Поворот до ±20°
    zoom_range=0.15,            # Масштабирование ±15%
    width_shift_range=0.2,      # Горизонтальный сдвиг 20%
    height_shift_range=0.2,     # Вертикальный сдвиг 20%
    shear_range=0.15,           # Сдвиг 15°
    horizontal_flip=True,       # Горизонтальное отражение
    fill_mode="nearest"
)
```

**Разделение данных:**
- Train/Test split: 80%/20%
- Стратификация по классам
- Random seed: 42

### Двухкомпонентная архитектура:

#### 1. Базовая модель (Base Model) - MobileNetV2

```python
baseModel = MobileNetV2(weights="imagenet", include_top=False,
                        input_tensor=Input(shape=(224, 224, 3)))
```

**Характеристики:**
- **Архитектура:** MobileNetV2 - современная сверточная, оптимизированная нейронная сеть
- **Входные данные:** Изображения размером 224×224×3 (RGB)
- **Веса:** Предобучена на датасете ImageNet (1.2 млн изображений, 1000 классов)
- **Включение верхних слоев:** include_top=False - исключает финальные классификационные слои

**Преимущества выбора MobileNetV2:**
- Высокая эффективность при небольшом количестве параметров
- Быстрая обработка в реальном времени
- Оптимизирована для embedded-систем и мобильных устройств

#### 2. Головная модель (Head Model) - Пользовательский классификатор

```python
headModel = baseModel.output
headModel = AveragePooling2D(pool_size=(7, 7))(headModel)
headModel = Flatten(name="flatten")(headModel)
headModel = Dense(128, activation="relu")(headModel)
headModel = Dropout(0.5)(headModel)
headModel = Dense(2, activation="softmax")(headModel)
```

**Слои головной модели:**

| Слой | Параметры | Назначение |
|------|-----------|------------|
| AveragePooling2D | pool_size=(7, 7) | Усреднение карт признаков для уменьшения размерности |
| Flatten | - | Преобразование 2D-данных в 1D-вектор |
| Dense | 128 нейронов, ReLU | Полносвязный слой для обучения специфичным признакам |
| Dropout | rate=0.5 | Регуляризация - исключение 50% нейронов для предотвращения переобучения |
| Dense | 2 нейрона, Softmax | Финальный классификационный слой |

Данная архитектура обеспечивает баланс между точностью классификации и производительностью, что критически важно для систем реального времени.

**Преимущества для проекта СИЗ:**
- Обучение за часы, а не недели
- Высокая точность даже на 2-5 тысячах изображений
- Устойчивость к различным условиям съемки
- Возможность легкого переобучения на другие признаки

### Обоснование структуры головного классификатора

```python
headModel = AveragePooling2D(pool_size=(7, 7))(headModel)  # Уменьшение размерности
headModel = Flatten()(headModel)
headModel = Dense(128, activation="relu")(headModel)       # Достаточная емкость для 2 классов
headModel = Dropout(0.5)(headModel)                        # Борьба с переобучением
headModel = Dense(2, activation="softmax")(headModel)      # Бинарная классификация
```

**Почему такая структура оптимальна:**
- **128 нейронов** — золотая середина: достаточно для сложных признаков, но не избыточно
- **Dropout 0.5** — эффективная регуляризация для предотвращения запоминания датасета
- **Softmax** — идеален для взаимоисключающих классов ("маска есть" / "маски нет")

## Сравнение с альтернативными архитектурами

Для системы автоматического контроля средств индивидуальной защиты (СИЗ) требуется архитектура, обеспечивающая оптимальный баланс между точностью, скоростью работы и эффективностью на edge-устройствах. Проведем анализ современных архитектур на основе актуальных научных исследований.

### 1. MobileNetV2 - текущий выбор

MobileNetV2 представляет собой сверточную нейронную сеть, основанную на архитектуре с инвертированными остаточными блоками (inverted residuals) и линейными бутылочными горлышками (linear bottlenecks). Ключевые особенности архитектуры включают использование depthwise separable convolutions для снижения вычислительной сложности, а также механизм расширения и сжатия каналов в остаточных блоках. Сеть оптимизирована для работы на мобильных и edge-устройствах при сохранении конкурентной точности.

**Преимущества для детекции СИЗ:**

- **Проверенная эффективность в реальных системах мониторинга**
  Согласно исследованию 2025 года, архитектура MobileNetV2 в связке с SSD демонстрирует высокую эффективность для задач автоматизированного мониторинга, достигая показателя точности 87.4% mAP. Это подтверждает пригодность архитектуры для развертывания в реальных системах с ограниченными вычислительными ресурсами, что характерно для систем контроля СИЗ [1].

- **Высокая точность в требовательных приложениях**
  В исследовании 2024 года модифицированная архитектура MobileNetV2 показала точность 97.73% при классификации медицинских изображений, что доказывает ее способность решать сложные задачи визуального распознавания даже в таких критически важных областях, как медицинская диагностика [2].

- **Эффективность работы с ограниченными данными**
  Исследование 2025 года подтверждает исключительную эффективность MobileNetV2 при работе с небольшими наборами данных. Архитектура позволяет достигать точности 98.6% в задачах тонкой классификации, что особенно важно для систем распознавания СИЗ, где сбор больших размеченных datasets часто затруднен [3].

- **Оптимизация производительности**
  Тот же источник [3] отмечает, что оптимизированные реализации MobileNetV2 позволяют сократить время обучения на 50-70% и время вывода на 10% по сравнению с базовой версией, что обеспечивает экономическую эффективность и практическую применимость системы.

- **Подтвержденная надежность архитектуры**
  Современные научные работы 2024-2025 годов продолжают активно использовать MobileNetV2 в прикладных решениях для edge-устройств, что свидетельствует о сохранении актуальности и надежности данной архитектуры для промышленного применения [1,2,3].

### 2. MobileNetV3 Large

**Архитектурное описание:**
MobileNetV3 Large представляет собой крупномасштабную версию архитектуры MobileNetV3, разработанную с применением нейроархитектурного поиска (NAS). Модель сохраняет базовые принципы MobileNetV2, включая inverted residuals и linear bottlenecks, но дополнена squeeze-and-excitation блоками и оптимизированными активационными функциями h-swish. Архитектура ориентирована на достижение максимальной точности при сохранении приемлемой производительности на мобильных устройствах.

### 3. MobileNetV3 Small

**Архитектурное описание:**
MobileNetV3 Small является компактной версией архитектуры, оптимизированной для максимального быстродействия и минимального потребления ресурсов. Как и в Large-версии, здесь применяется нейроархитектурный поиск и те же основные структурные элементы, но с уменьшенной шириной сети и оптимизированной конфигурацией блоков. Модель предназначена для приложений с экстремальными ограничениями по вычислительным ресурсам и энергопотреблению.

### 4. EfficientNet

**Архитектурное описание:**
EfficientNet использует инновационный подход составного масштабирования (compound scaling), равномерно увеличивая глубину, ширину и разрешение входных данных. Архитектура основана на mobile inverted bottleneck convolution (MBConv) - технике, также используемой в MobileNetV2. Систематический подход к масштабированию позволяет достигать высокой точности при оптимальном использовании вычислительных ресурсов, однако требует тщательной настройки гиперпараметров.

### 5. Vision Transformers

**Архитектурное описание:**
Vision Transformers адаптируют архитектуру трансформеров, изначально разработанную для обработки естественного языка, к задачам компьютерного зрения. Основной принцип заключается в разбиении изображения на патчи и обработке их как последовательности данных с помощью механизмов внимания. Архитектура обеспечивает глобальный контекст изображения, но предъявляет высокие требования к вычислительным ресурсам и объему тренировочных данных, что ограничивает ее применение в edge-устройствах.

### Таблица сравнения архитектур

| Архитектура | Ключевой принцип / Структура | Показатели эффективности (ImageNet) | Основные преимущества | Вывод для системы контроля СИЗ |
|-------------|------------------------------|-------------------------------------|----------------------|-------------------------------|
| **MobileNetV2** | Inverted Residuals с Linear Bottlenecks. Основной блок: слой расширения (pointwise conv), depthwise convolution, слой проекции (pointwise conv, линейная активация). Остаточные связи между bottleneck-слоями. | Точность Top-1: 71.3%<br>Точность Top-5: 90.1% [5]<br>Параметры: 3.5 млн [5]<br>Время вывода: 25.9 мс [5] | Проверенная надежность, низкие требования к ресурсам. Эффективное использование параметров, оптимизирована для мобильных устройств. | **Оптимальный выбор.** Сочетает достаточную точность с возможностью работы в реальном времени на edge-устройствах. |
| **MobileNetV3 Large** | Сочетание NAS (Hardware-Aware NAS) и NetAdapt алгоритма с наследием V1/V2. Добавлены Squeeze-and-Excitation блоки и h-swish активация в глубоких слоях. | Точность Top-1: 75.6% [4]<br>Параметры: 5.4 млн [4]<br>Время вывода: 51.2 мс [4] | Улучшенная точность классификации, аппаратная оптимизация благодаря автоматизированному поиску архитектуры. | Альтернатива для задач с повышенными требованиями к точности. Увеличенное время вывода может быть критично для систем реального времени. |
| **MobileNetV3 Small** | Сочетание NAS (Hardware-Aware NAS) и NetAdapt алгоритма с наследием V1/V2. Добавлены Squeeze-and-Excitation блоки и h-swish активация в глубоких слоях. | Точность Top-1: 68.1% [4]<br>Параметры: 2.9 млн [4]<br>Время вывода: 15.8 мс [4] | Максимальная скорость работы, минимальные требования к ресурсам. | Решение для систем с экстремальными ограничениями по вычислительным ресурсам. Сниженная точность может быть недостаточной для надежного контроля СИЗ. |
| **EfficientNet** | Compound Scaling: сбалансированное масштабирование глубины, ширины и разрешения изображения. | Точность Top-1: 77.1% (B0)<br>Точность Top-1: 84.4% (B7)<br>Параметры: ~5.3 млн (B0) | Системное масштабирование, высокая точность классификации. | Специализированное решение. Избыточен для большинства задач контроля СИЗ, требует больше ресурсов. |
| **Vision Transformer** | Разбиение изображения на патчи, обработка последовательности патчей энкодером Transformer со self-attention. | Точность: Сопоставима с лучшими CNN-моделями (например, достигает парето-оптимальности по точности и скорости) [6]<br>Параметры: Модели могут быть очень большими, например, ViT-Huge содержит 632 млн параметров [7] | Глобальный контекст изображения, перспективная архитектура. | Экспериментальная технология. Непрактична для реальных систем из-за высоких требований к данным и вычислителям. |

## Заключение

Для системы автоматического контроля СИЗ архитектура MobileNetV2 демонстрирует наилучший баланс между точностью обнаружения, скоростью работы в реальном времени и эффективностью использования ресурсов, что подтверждается успешным применением в аналогичных промышленных системах мониторинга.

Альтернативные архитектуры предлагают незначительные улучшения отдельных метрик, но не обеспечивают комплексного превосходства для задачи детекции СИЗ в реальных условиях.

## Источники

1. Amoako E. et al. Application of SSD-MobileNetV2 for automated defect detection in masonry bridges using AI and IoT //Advances in Bridge Engineering. – 2025. – Т. 6. – №. 1. – С. 31.

2. Zhou G. et al. Optimizing MobileNetV2 for improved accuracy in early gastric cancer detection based on dynamic pelican optimizer //Heliyon. – 2024. – Т. 10. – №. 16.

3. Martins O. O., Oosthuizen C. C., Desai D. A. Evaluating unified training optimisations for MobileNetV2: Efficiency-accuracy trade-offs in fine-grained dog breed classification //Discover Applied Sciences. – 2025. – Т. 7. – №. 11. – С. 1240.

4. Keras: MobileNet and MobileNetV2 [Электронный ресурс]. – URL: https://keras.io/api/applications/mobilenet/ (дата обращения: 15.10.2025).

5. Keras: Applications API [Электронный ресурс]. – URL: https://keras.io/api/applications/ (дата обращения: 15.10.2025).

6. Nauen T. C. et al. Which Transformer to Favor: A Comparative Analysis of Efficiency in Vision Transformers //2025 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV). – IEEE, 2025. – С. 6955-6966.

7. Saha S., Xu L. Vision transformers on the edge: A comprehensive survey of model compression and acceleration strategies //Neurocomputing. – 2025. – С. 130417.
